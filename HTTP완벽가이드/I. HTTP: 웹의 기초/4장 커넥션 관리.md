# 4장. 커넥션 관리

## 4.1 TCP 커넥션

### 핵심 개념
HTTP는 TCP/IP 위에서 동작합니다. HTTP 메시지를 보내기 전에 먼저 TCP 커넥션을 수립해야 합니다.

### TCP/IP 계층 구조

```
애플리케이션 계층: HTTP, FTP, SMTP
       ↓
전송 계층: TCP (신뢰성 보장)
       ↓
네트워크 계층: IP (라우팅)
       ↓
데이터링크 계층: Ethernet, WiFi
```

### TCP의 특징

**신뢰성 있는 전송:**
- 데이터 순서 보장
- 손실된 패킷 재전송
- 흐름 제어

```
[클라이언트]              [서버]
    │                      │
    │─── 패킷1 ──────────→│ ✓
    │─── 패킷2 ──────────→│ ✗ (손실)
    │─── 패킷3 ──────────→│ ✓
    │                      │
    │←── 재전송 요청 ──────│
    │─── 패킷2 ──────────→│ ✓
    │                      │
    [순서대로 재조립: 1,2,3]
```

### TCP 커넥션 수립 (3-way Handshake)

```
클라이언트           서버
   │                 │
   │─── SYN ───────→│  1. 연결 요청
   │   (seq=100)     │
   │                 │
   │←── SYN+ACK ────│  2. 요청 수락
   │   (seq=200,     │
   │    ack=101)     │
   │                 │
   │─── ACK ───────→│  3. 확인
   │   (ack=201)     │
   │                 │
   [연결 수립 완료]
```

**시간 소요:**
- 1 RTT (Round Trip Time) 소요
- RTT = 클라이언트 → 서버 → 클라이언트 왕복 시간

```javascript
// Frontend에서는 보이지 않지만...
fetch('https://api.example.com/users')

// 내부적으로 일어나는 일:
// 1. DNS 조회 (api.example.com → IP 주소)
// 2. TCP 3-way handshake (약 1 RTT)
// 3. TLS handshake (HTTPS의 경우, 약 1-2 RTT)
// 4. HTTP 요청 전송
// 5. HTTP 응답 수신
```

### RTT의 영향

```
서울 → 서울 서버: 10ms RTT
서울 → 도쿄 서버: 40ms RTT
서울 → 미국 서버: 180ms RTT
서울 → 유럽 서버: 280ms RTT

// 미국 서버에 HTTPS 요청 시:
DNS 조회: 180ms
TCP handshake: 180ms
TLS handshake: 360ms (2 RTT)
HTTP 요청/응답: 180ms
────────────────────
총 900ms! (거의 1초)
```

**해결책:**
- CDN 사용 (CloudFront, Cloudflare)
- HTTP/2 (연결 재사용)
- HTTP/3 (QUIC, 0-RTT)

```javascript
// CloudFront 사용 시
// 서울 사용자 → 서울 엣지 로케이션 (20ms)
// 첫 요청만 원본까지 가고, 이후는 캐시 사용

// 개선 효과
// Before: 900ms
// After: 20ms (45배 빠름!)
```

---

## 4.2 TCP의 성능에 대한 고려

### HTTP 트랜잭션 지연

전체 지연 = DNS 조회 + TCP 연결 + 요청 전송 + 처리 + 응답 전송

```
Timeline:
0ms     DNS 조회 시작
100ms   DNS 조회 완료
100ms   TCP 연결 시작
180ms   TCP 연결 완료 (1 RTT)
180ms   TLS 협상 시작
360ms   TLS 협상 완료 (2 RTT)
360ms   HTTP 요청 전송
370ms   요청 도착 (10ms 전송 시간)
370ms   서버 처리 시작
400ms   서버 처리 완료 (30ms 처리)
400ms   응답 전송 시작
410ms   응답 도착 (10ms 전송 시간)
──────────────────────────
총 410ms
```

### 성능 병목 구간

```javascript
// Performance API로 측정
const perfData = performance.getEntriesByType('navigation')[0];

console.log('DNS 조회:', perfData.domainLookupEnd - perfData.domainLookupStart);
console.log('TCP 연결:', perfData.connectEnd - perfData.connectStart);
console.log('TLS 협상:', perfData.secureConnectionStart ? 
  perfData.connectEnd - perfData.secureConnectionStart : 0);
console.log('응답 대기:', perfData.responseStart - perfData.requestStart);
console.log('응답 수신:', perfData.responseEnd - perfData.responseStart);

// Resource Timing API로 개별 리소스 측정
performance.getEntriesByType('resource').forEach(resource => {
  console.log(resource.name);
  console.log('  총 시간:', resource.duration);
  console.log('  DNS:', resource.domainLookupEnd - resource.domainLookupStart);
  console.log('  TCP:', resource.connectEnd - resource.connectStart);
  console.log('  다운로드:', resource.responseEnd - resource.responseStart);
});
```

### TCP Slow Start (느린 시작)

TCP는 처음에는 적은 양의 데이터만 보내고, 점차 늘려갑니다.

```
전송 속도 (패킷 수)
    │
 16 │          ┌───
  8 │      ┌───┘
  4 │  ┌───┘
  2 │┌─┘
  1 ││
    └───────────→ 시간
     RTT 단위
```

**영향:**
- 작은 파일: Slow Start 영향 큼
- 큰 파일: 점차 속도 증가
- 연결 재사용이 중요한 이유

```javascript
// 100KB 파일 전송
// 새 연결: Slow Start → 느림
// 기존 연결: 이미 속도 증가됨 → 빠름

// 여러 작은 파일 vs 하나의 큰 파일
// HTTP/1.1: 번들링 유리 (연결당 Slow Start 1회)
// HTTP/2: 작은 파일 여러 개 OK (연결 하나로 멀티플렉싱)
```

### Nagle 알고리즘

작은 패킷들을 모아서 한 번에 전송

```
Without Nagle:
패킷1 (10 bytes) → 전송
패킷2 (20 bytes) → 전송
패킷3 (15 bytes) → 전송
→ 패킷 3개 (헤더 오버헤드 큼)

With Nagle:
패킷1 (10 bytes) ┐
패킷2 (20 bytes) ├─→ 모아서 전송 (45 bytes)
패킷3 (15 bytes) ┘
→ 패킷 1개 (효율적)
```

**문제점:**
- 실시간 애플리케이션에는 부적합 (지연 발생)
- HTTP에서는 대부분 비활성화

---

## 4.3 HTTP 커넥션 관리

### 커넥션 헤더

```javascript
// HTTP/1.0 - 기본이 close
Connection: close  // 응답 후 연결 종료

// HTTP/1.1 - 기본이 keep-alive
Connection: keep-alive  // 연결 유지 (생략 가능)
```

### 순차 커넥션 (Serial Connections)

한 번에 하나씩 처리

```
Timeline:
0ms    파일1 요청
100ms  파일1 응답
100ms  파일2 요청
200ms  파일2 응답
200ms  파일3 요청
300ms  파일3 응답
──────────────
총 300ms
```

**단점:**
- 느림
- 네트워크 대역폭 낭비

```javascript
// 순차 처리 (안티패턴)
const user = await fetch('/api/users/123').then(r => r.json());
const posts = await fetch('/api/posts').then(r => r.json());
const comments = await fetch('/api/comments').then(r => r.json());
// 총 시간: 100ms + 100ms + 100ms = 300ms
```

---

## 4.4 병렬 커넥션

### 병렬 커넥션 (Parallel Connections)

여러 커넥션을 동시에 사용

```
Timeline:
0ms    파일1 요청 ─────→ 100ms 응답
0ms    파일2 요청 ─────→ 100ms 응답
0ms    파일3 요청 ─────→ 100ms 응답
───────────────────────
총 100ms (3배 빠름!)
```

```javascript
// 병렬 처리
const [user, posts, comments] = await Promise.all([
  fetch('/api/users/123').then(r => r.json()),
  fetch('/api/posts').then(r => r.json()),
  fetch('/api/comments').then(r => r.json())
]);
// 총 시간: 100ms (가장 느린 것 기준)
```

### 브라우저의 동시 연결 제한

```
브라우저별 동시 연결 수 (도메인당):
- Chrome: 6개
- Firefox: 6개
- Safari: 6개
- Edge: 6개

// 7개 요청 시
요청1,2,3,4,5,6 → 동시 실행
요청7 → 대기 → 앞의 요청 완료 후 실행
```

**회피 방법 (HTTP/1.1 시대):**

```javascript
// Domain Sharding (도메인 샤딩)
// 여러 도메인 사용으로 연결 수 증가
<img src="https://cdn1.example.com/img1.jpg">
<img src="https://cdn2.example.com/img2.jpg">
<img src="https://cdn3.example.com/img3.jpg">
// 도메인 3개 × 6 연결 = 18개 동시 연결 가능

// 하지만 HTTP/2에서는 불필요 (오히려 해로움)
```

### 병렬 커넥션의 단점

1. **클라이언트 리소스 소비**
   - 메모리 사용 증가
   - CPU 사용 증가

2. **서버 부하 증가**
   - 연결당 메모리 필요
   - 많은 클라이언트 × 많은 연결 = 서버 과부하

3. **네트워크 대역폭 경쟁**
   - 여러 연결이 대역폭을 나눠 씀
   - 실제로는 N배 빠르지 않음

```javascript
// 실제 테스트
// 순차: 1개 연결, 1Mbps → 100ms
// 병렬: 4개 연결, 1Mbps 공유 → 각 250Kbps → 여전히 100ms
// (대역폭이 병목이면 병렬도 소용없음)
```

---

## 4.5 지속 커넥션

### Keep-Alive 커넥션

연결을 재사용해서 TCP 설정 비용 절약

```
Without Keep-Alive (HTTP/1.0):
요청1 → 연결 생성 → 응답1 → 연결 종료
요청2 → 연결 생성 → 응답2 → 연결 종료
요청3 → 연결 생성 → 응답3 → 연결 종료
총 시간: (연결 시간 + 요청/응답) × 3

With Keep-Alive (HTTP/1.1):
연결 생성 → 요청1 → 응답1 → 요청2 → 응답2 → 요청3 → 응답3 → 연결 종료
총 시간: 연결 시간 + (요청/응답) × 3
```

**성능 향상:**
```
RTT = 100ms

Without Keep-Alive:
- 요청 3개
- 각 요청마다 TCP 연결 (100ms)
- 총: 300ms + 실제 데이터 전송 시간

With Keep-Alive:
- 요청 3개
- TCP 연결 1회 (100ms)
- 총: 100ms + 실제 데이터 전송 시간

절약: 200ms
```

### Keep-Alive 헤더

```http
// 요청
GET /api/users HTTP/1.1
Host: api.example.com
Connection: keep-alive

// 응답
HTTP/1.1 200 OK
Connection: keep-alive
Keep-Alive: timeout=5, max=100

// timeout=5: 5초간 요청 없으면 연결 종료
// max=100: 최대 100개 요청까지 허용
```

```javascript
// Frontend에서는 브라우저가 자동 관리
// 같은 도메인에 여러 요청 → 자동으로 연결 재사용

await fetch('/api/users');     // 연결 생성
await fetch('/api/posts');     // 연결 재사용 ✓
await fetch('/api/comments');  // 연결 재사용 ✓

// 5초 대기...

await fetch('/api/users');     // 새 연결 생성 (타임아웃)
```

### 지속 커넥션의 장점

1. **연결 설정 비용 감소**
   - TCP handshake 1회만

2. **TCP Slow Start 회피**
   - 이미 최적 속도로 전송 중

3. **연결 수 감소**
   - 서버 부하 감소

### 지속 커넥션 관리

**Nginx 설정:**
```nginx
http {
    # Keep-Alive 설정
    keepalive_timeout 65s;      # 65초간 유지
    keepalive_requests 100;      # 최대 100개 요청
    
    # Upstream 연결 풀
    upstream backend {
        server backend1.example.com;
        server backend2.example.com;
        keepalive 32;  # 32개 연결 유지
    }
    
    server {
        location /api {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Connection "";  # Keep-Alive 활성화
        }
    }
}
```

**서버 리소스 고려:**
```
동시 접속자 1,000명
각자 Keep-Alive 연결 유지
→ 1,000개 연결 유지 필요

메모리: 연결당 ~10KB
→ 1,000 × 10KB = 10MB

FD(File Descriptor) 한계:
- Linux 기본값: 1024
- 조정 필요: ulimit -n 10000
```

---

## 4.6 파이프라인 커넥션

### HTTP 파이프라이닝

응답을 기다리지 않고 여러 요청을 연속으로 전송

```
Without Pipelining:
요청1 → 응답1 → 요청2 → 응답2 → 요청3 → 응답3
│────100ms────│────100ms────│────100ms────│
총 300ms

With Pipelining:
요청1 → 요청2 → 요청3 → 응답1 → 응답2 → 응답3
│──────────────100ms──────────────│
총 100ms (3배 빠름!)
```

### 파이프라이닝의 제약

1. **순서 보장 필요**
   - 응답은 요청 순서대로 와야 함
   - 느린 응답이 뒤의 응답을 막음 (HOL Blocking)

```
요청1 (빠름) → 요청2 (느림) → 요청3 (빠름)
       ↓
응답1 완료
       ↓
응답2 처리 중... (블로킹!)
       ↓
응답3 대기 중... (준비됐지만 대기)
```

2. **멱등성 필요**
   - GET, HEAD 등 안전한 메서드만 권장
   - POST는 위험 (재시도 시 중복 생성)

3. **브라우저 지원 부족**
   - Chrome: 비활성화
   - Firefox: 비활성화
   - 실무에서 거의 사용 안됨

**대안: HTTP/2**
```javascript
// HTTP/2에서는 파이프라이닝 불필요
// 멀티플렉싱으로 모든 요청/응답을 병렬 처리
// 순서 무관, HOL Blocking 없음
```

---

## 4.7 커넥션 끊기에 대한 미스터리

### TCP 커넥션 종료 (4-way Handshake)

```
클라이언트           서버
   │                 │
   │─── FIN ───────→│  1. 종료 요청
   │                 │
   │←── ACK ────────│  2. 확인
   │                 │
   │←── FIN ────────│  3. 종료 요청
   │                 │
   │─── ACK ───────→│  4. 확인
   │                 │
   [연결 종료 완료]
```

### 절반 끊기 (Half-Close)

한쪽만 먼저 종료

```
클라이언트           서버
   │                 │
   │─── FIN ───────→│  클라이언트: "나는 더 안 보낼게"
   │                 │
   │←── ACK ────────│  서버: "알았어, 근데 나는 보낼게"
   │                 │
   │←── 데이터 ──────│  서버가 계속 데이터 전송 가능
   │←── 데이터 ──────│
   │                 │
   │←── FIN ────────│  서버: "나도 다 보냈어"
   │                 │
   │─── ACK ───────→│  클라이언트: "알았어"
   │                 │
```

### 리셋 (RST)

비정상 종료

```
클라이언트           서버
   │                 │
   │─── 요청 ───────→│
   │                 │
   │←── RST ────────│  즉시 종료!
   │                 │
```

**RST 발생 원인:**
- 존재하지 않는 포트 접근
- 서버 프로세스 강제 종료
- 방화벽에 의한 차단

```javascript
// Frontend에서 RST는 네트워크 에러로 나타남
fetch('/api/data')
  .catch(error => {
    console.error(error);  // TypeError: Failed to fetch
  });
```

### 우아한 종료 (Graceful Shutdown)

```javascript
// Node.js 서버 예시
const server = http.createServer(app);

// SIGTERM 시그널 수신
process.on('SIGTERM', () => {
  console.log('종료 신호 수신, 우아한 종료 시작');
  
  server.close(() => {
    console.log('모든 연결 종료 완료');
    process.exit(0);
  });
  
  // 30초 타임아웃
  setTimeout(() => {
    console.error('강제 종료');
    process.exit(1);
  }, 30000);
});

// 우아한 종료 과정:
// 1. 새 요청 거부
// 2. 기존 요청 처리 완료 대기
// 3. 모든 연결 종료
// 4. 프로세스 종료
```

**AWS ALB의 Connection Draining:**
```
배포 시나리오:
1. 새 인스턴스 시작
2. ALB가 새 인스턴스로 트래픽 라우팅 시작
3. 기존 인스턴스를 "Draining" 상태로 전환
   - 새 요청 안 받음
   - 기존 요청만 처리
   - 타임아웃: 300초 (기본값)
4. 기존 요청 모두 완료 후 인스턴스 종료
```

### 타임아웃

**연결 타임아웃:**
```javascript
// Fetch API - 기본 타임아웃 없음 (무한 대기)
const controller = new AbortController();
const timeoutId = setTimeout(() => controller.abort(), 5000);

fetch('/api/data', { signal: controller.signal })
  .then(response => {
    clearTimeout(timeoutId);
    return response.json();
  })
  .catch(error => {
    if (error.name === 'AbortError') {
      console.error('요청 타임아웃');
    }
  });

// 재사용 가능한 함수
function fetchWithTimeout(url, options = {}, timeout = 5000) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeout);
  
  return fetch(url, { ...options, signal: controller.signal })
    .finally(() => clearTimeout(timeoutId));
}

// 사용
await fetchWithTimeout('/api/data', {}, 3000);  // 3초 타임아웃
```

**Idle 타임아웃:**
```
Keep-Alive 연결이 유휴 상태일 때

클라이언트           서버
   │                 │
   │───────────────→│  요청/응답
   │                 │
   [60초 idle...]    │
   │                 │
   │                 │  서버: "60초간 요청 없음, 연결 종료"
   │←── FIN ────────│
```

**읽기 타임아웃:**
```
응답이 너무 느릴 때

클라이언트           서버
   │                 │
   │─── 요청 ───────→│
   │                 │
   │                 │  서버 처리 중...
   [30초 경과...]    │
   │                 │
   타임아웃 발생      │
```

**Nginx 타임아웃 설정:**
```nginx
http {
    # 클라이언트 연결 타임아웃
    client_body_timeout 60s;    # 요청 본문 읽기
    client_header_timeout 60s;  # 요청 헤더 읽기
    
    # Keep-Alive 타임아웃
    keepalive_timeout 65s;
    
    # 프록시 타임아웃
    proxy_connect_timeout 60s;  # Backend 연결
    proxy_send_timeout 60s;     # Backend로 전송
    proxy_read_timeout 60s;     # Backend 응답 대기
    
    # 전송 타임아웃
    send_timeout 60s;           # 클라이언트로 전송
}
```

---

## 4.8 HTTP/2의 개선

### 멀티플렉싱 (Multiplexing)

하나의 TCP 연결로 여러 요청/응답 동시 처리

```
HTTP/1.1:
연결1: 요청1 → 응답1 → 요청2 → 응답2
연결2: 요청3 → 응답3 → 요청4 → 응답4
연결3: 요청5 → 응답5 → 요청6 → 응답6

HTTP/2:
연결1: 요청1,2,3,4,5,6 → 응답1,2,3,4,5,6 (순서 무관)
       └──────────────────────────────┘
              하나의 TCP 연결
```

**장점:**
```javascript
// HTTP/1.1 - 도메인당 6개 연결 제한
// 7번째 요청은 대기 필요

// HTTP/2 - 연결 1개로 무제한 요청
// 모든 요청이 동시 전송 가능
await Promise.all([
  fetch('/api/1'),
  fetch('/api/2'),
  // ... 100개 요청도 OK
  fetch('/api/100')
]);
```

### 스트림 우선순위 (Stream Prioritization)

중요한 리소스 먼저 전송

```
Priority:
HTML (최우선) → CSS → JavaScript → 이미지

HTTP/2 스트림:
스트림1 (HTML): ████████████ (우선순위 높음)
스트림2 (CSS):  ████████     (우선순위 중간)
스트림3 (이미지): ████        (우선순위 낮음)
```

### 헤더 압축 (HPACK)

반복되는 헤더를 압축

```
HTTP/1.1:
요청1: Host: api.example.com, Authorization: Bearer token..., Accept: application/json
요청2: Host: api.example.com, Authorization: Bearer token..., Accept: application/json
요청3: Host: api.example.com, Authorization: Bearer token..., Accept: application/json
→ 매번 동일한 헤더 전송 (비효율)

HTTP/2 (HPACK):
요청1: Host: api.example.com, Authorization: Bearer token..., Accept: application/json
요청2: [참조: 헤더 1번]  (압축!)
요청3: [참조: 헤더 1번]  (압축!)
→ 50~90% 압축률
```

### 서버 푸시 (Server Push)

요청하지 않은 리소스를 미리 전송

```
Without Server Push:
클라이언트: HTML 요청
서버: HTML 응답
클라이언트: HTML 파싱 → CSS 발견 → CSS 요청
서버: CSS 응답
클라이언트: CSS 파싱 → JS 발견 → JS 요청
서버: JS 응답

With Server Push:
클라이언트: HTML 요청
서버: HTML 응답 + CSS 푸시 + JS 푸시 (동시에!)
클라이언트: 모든 리소스 즉시 사용 가능
```

**실무 활용:**
```nginx
# Nginx에서 HTTP/2 Server Push
server {
    listen 443 ssl http2;
    
    location = /index.html {
        http2_push /css/style.css;
        http2_push /js/app.js;
    }
}
```

**주의사항:**
- 캐시 확인 불가 (이미 있는 파일도 푸시)
- 대역폭 낭비 가능
- 실무에서는 신중하게 사용

---

## 토론 주제 (Frontend 개발자 관점)

### 1. HTTP/1.1 최적화 vs HTTP/2 최적화
**주제**: "번들링 전략, HTTP/2 시대에도 유효한가?"

**HTTP/1.1 최적화 (과거):**
```javascript
// 파일 합치기 (번들링)
app.js = [
  component1.js,
  component2.js,
  component3.js,
  // ... 100개 파일을 1개로
]
// 이유: 연결 수 제한, TCP Slow Start

// CSS 스프라이트
// 100개 아이콘 → 1개 이미지

// Domain Sharding
cdn1.example.com
cdn2.example.com
cdn3.example.com
```

**HTTP/2 최적화 (현재):**
```javascript
// 작은 파일 여러 개 OK
// 멀티플렉싱으로 동시 전송
// 오히려 선택적 로딩에 유리

// 하지만...
// - 파싱 오버헤드 (JS 100개 vs 1개)
// - HTTP/2 미지원 브라우저는?
```

**토론 포인트**
- 실제 프로젝트에서 어떤 전략?
- Code Splitting vs Bundle?
- 측정 결과 공유

### 2. API 호출 병렬화 전략
**주제**: "Promise.all vs Sequential, 어떻게 선택하나요?"

**시나리오별 전략**
```javascript
// 1. 독립적인 데이터 - 병렬
const [users, posts, tags] = await Promise.all([
  fetchUsers(),
  fetchPosts(),
  fetchTags()
]);

// 2. 의존 관계 - 순차
const user = await fetchUser(userId);
const posts = await fetchUserPosts(user.id);
const comments = await fetchPostComments(posts[0].id);

// 3. 일부 의존 - 혼합
const user = await fetchUser(userId);
const [posts, followers] = await Promise.all([
  fetchUserPosts(user.id),
  fetchUserFollowers(user.id)
]);

// 4. Race Condition 주의
// 병렬 업데이트 시 충돌 가능
```

**토론 포인트**
- 에러 처리 (Promise.all vs Promise.allSettled)
- 타임아웃 설정
- 우선순위 관리

### 3. 연결 타임아웃 설정
**주제**: "적절한 타임아웃 시간은?"

**환경별 타임아웃**
```javascript
// 로컬 개발
timeout: 30000  // 30초 (디버깅 여유)

// QA/Staging
timeout: 10000  // 10초

// 프로덕션
timeout: 5000   // 5초 (빠른 실패)

// 특수 케이스
파일 업로드: 120000  // 2분
보고서 생성: 60000   // 1분
일반 API: 5000       // 5초
```

**재시도 전략**
```javascript
// Exponential Backoff
시도1: 1초 후
시도2: 2초 후
시도3: 4초 후
최대: 3회 재시도

// 어떤 에러에 재시도?
// 5xx, 네트워크 에러 → 재시도
// 4xx → 재시도 안함
```

### 4. Keep-Alive 연결 관리
**주제**: "SPA에서 연결이 끊어지는 경험 있나요?"

**문제 상황**
```javascript
// 사용자가 페이지를 1시간 방치
// Keep-Alive 타임아웃 (60초)
// 다음 API 호출 시 연결 없음
// → 새 연결 생성으로 느려짐

// 해결책?
// 1. Heartbeat (주기적 핑)
setInterval(() => {
  fetch('/api/ping');
}, 30000);  // 30초마다

// 2. 재연결 자동화 (브라우저가 처리)
// 3. WebSocket으로 전환?
```

### 5. Prefetch와 Preconnect
**주제**: "리소스 힌트, 얼마나 효과적인가요?"

**리소스 힌트 종류**
```html
<!-- DNS Prefetch -->
<link rel="dns-prefetch" href="https://api.example.com">

<!-- Preconnect (DNS + TCP + TLS) -->
<link rel="preconnect" href="https://api.example.com">

<!-- Prefetch (다음 페이지 리소스) -->
<link rel="prefetch" href="/next-page.js">

<!-- Preload (현재 페이지 필수 리소스) -->
<link rel="preload" href="/critical.css" as="style">
```

**측정 결과 공유**
```javascript
// Before Preconnect
첫 API 호출: 800ms (DNS + TCP + TLS + 요청/응답)

// After Preconnect
첫 API 호출: 200ms (요청/응답만)

// 절약: 600ms!
```

**주의사항**
- 너무 많으면 오히려 느려짐
- 실제 사용할 것만 preconnect
- 측정으로 검증

### 6. HTTP/3 (QUIC) 도입
**주제**: "HTTP/3로 전환할 때가 됐나요?"

**HTTP/3 특징**
```
TCP 문제:
패킷 손실 시 모든 스트림 블로킹 (HOL Blocking)

QUIC (UDP 기반):
스트림별 독립 전송
패킷 손실 시 해당 스트림만 영향

0-RTT:
첫 연결도 빠름 (캐시 활용)
```

**도입 고려사항**
```javascript
// 브라우저 지원
// Chrome: ✅
// Firefox: ✅
// Safari: ✅

// CDN 지원
// CloudFront: ✅
// Cloudflare: ✅

// 실제 체감 차이는?
// 모바일, 불안정한 네트워크에서 효과
```

### 7. Connection Pool 관리
**주제**: "Backend 연결 풀 크기는 어떻게 설정하나요?"

**Node.js HTTP Agent**
```javascript
import http from 'http';
import https from 'https';

const httpAgent = new http.Agent({
  keepAlive: true,
  maxSockets: 50,        // 호스트당 최대 연결 수
  maxFreeSockets: 10,    // Keep-Alive 유지 수
  timeout: 60000,        // 소켓 타임아웃
});

const httpsAgent = new https.Agent({
  keepAlive: true,
  maxSockets: 50,
});

// axios에 적용
axios.create({
  httpAgent,
  httpsAgent
});
```

**적정 크기 계산**
```
동시 요청 수 = TPS × 평균 응답시간

예시:
- TPS: 100 (초당 100 요청)
- 응답시간: 0.1초
- 필요 연결: 100 × 0.1 = 10개

여유를 두고 2~3배: 20~30개
```

---

## 전체 요약

### HTTP 성능 최적화 체크리스트

**연결 최적화:**
- ✅ HTTP/2 (또는 HTTP/3) 활성화
- ✅ Keep-Alive 사용
- ✅ CDN 활용 (CloudFront, Cloudflare)
- ✅ DNS Prefetch / Preconnect

**요청 최적화:**
- ✅ 병렬 요청 (Promise.all)
- ✅ 불필요한 요청 제거
- ✅ 캐싱 활용 (Cache-Control, ETag)
- ✅ 압축 (gzip, brotli)

**코드 최적화:**
```javascript
// Bad
for (const id of userIds) {
  await fetchUser(id);  // 순차
}

// Good
await Promise.all(
  userIds.map(id => fetchUser(id))  // 병렬
);
```

**모니터링:**
```javascript
// Performance API 활용
const perfData = performance.getEntriesByType('navigation')[0];
console.log('DNS:', perfData.domainLookupEnd - perfData.domainLookupStart);
console.log('TCP:', perfData.connectEnd - perfData.connectStart);
console.log('TLS:', perfData.connectEnd - perfData.secureConnectionStart);
console.log('TTFB:', perfData.responseStart - perfData.requestStart);
```

